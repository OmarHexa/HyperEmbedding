{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d5e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "from utils import transforms as my_transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "\n",
    "H2GIGA_DIR='../Data'\n",
    "\n",
    "\n",
    "args = dict(\n",
    "\n",
    "    cuda=True,\n",
    "    display=True,\n",
    "\n",
    "    save=True,\n",
    "    save_dir='./test_deepLabv3_2',\n",
    "    checkpoint_path='./deepLabv3/checkpoint.pth',\n",
    "    color_map={0:(0,0,0),1: (21, 176, 26), 2:(5, 73, 7),3: (170, 166, 98),4: (229, 0, 0), 5: (140, 0, 15)},\n",
    "    num_class = 6,\n",
    "    dataset= { \n",
    "        'name': 'H2giga',\n",
    "        'kwargs': {\n",
    "            'root_dir': H2GIGA_DIR,\n",
    "            'type': '20220715',\n",
    "            'class_id': None,            \n",
    "            'transform': my_transforms.get_transform([\n",
    "                {\n",
    "                    'name': 'ToTensor',\n",
    "                    'opts': {\n",
    "                        'keys': ('image','instance', 'label'),\n",
    "                        'type': (torch.FloatTensor, torch.ByteTensor, torch.ByteTensor),\n",
    "                    }\n",
    "                },\n",
    "            ]),\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    return copy.deepcopy(args)\n",
    "def prepare_model(num_classes=6):\n",
    "    model = deeplabv3_resnet50(weights='DEFAULT')\n",
    "    model.classifier[4] = nn.Conv2d(256, num_classes, 1)\n",
    "    model.aux_classifier[4] = nn.Conv2d(256, num_classes, 1)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf60c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import test_config\n",
    "import torch\n",
    "from datasets import get_dataset\n",
    "from models import get_model\n",
    "from utils.utils import Cluster,Visualizer,Metrics\n",
    "from skimage.color import label2rgb\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "   \n",
    "args = get_args()\n",
    "\n",
    "\n",
    "def begin_test(args,n_sigma=2):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    if args['save']:\n",
    "        if not os.path.exists(args['save_dir']):\n",
    "            os.makedirs(args['save_dir'])\n",
    "\n",
    "    # set device\n",
    "    device = torch.device(\"cuda:0\" if args['cuda'] else \"cpu\")\n",
    "\n",
    "    # dataloader\n",
    "    dataset = get_dataset(args['dataset']['name'], args['dataset']['kwargs'])\n",
    "    dataset_it = torch.utils.data.DataLoader(\n",
    "                                dataset, \n",
    "                                batch_size=1, \n",
    "                                shuffle=False, \n",
    "                                drop_last=False, \n",
    "                                num_workers=2, \n",
    "                                pin_memory=True if args['cuda'] else False)\n",
    "\n",
    "    # load model\n",
    "    model = prepare_model(args[\"num_class\"])\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    num_class = 5\n",
    "\n",
    "    # load snapshot\n",
    "    if os.path.exists(args['checkpoint_path']):\n",
    "        state = torch.load(args['checkpoint_path'])\n",
    "#         state = torch.load(args['checkpoint_path'], map_location='cpu')\n",
    "        model.load_state_dict(state['model_state_dict'], strict=True)\n",
    "    else:\n",
    "        assert False, 'checkpoint_path {} does not exist!'.format(args['checkpoint_path'])\n",
    "#     print(model.device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Visualizer\n",
    "    visualizer = Visualizer(args)\n",
    "    metrics = Metrics(num_class=num_class)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for sample in tqdm(dataset_it):\n",
    "\n",
    "            im = sample['image'].to(device)\n",
    "            label = sample['label'].squeeze()\n",
    "        \n",
    "            output = model(im)\n",
    "            out = output[\"out\"][0]\n",
    "            class_pred = visualizer.prepare_pred(out)\n",
    "            pred_score = out[1:]\n",
    "            metrics.add(label.numpy(),class_pred.cpu().numpy(),pred_score.cpu().numpy())\n",
    "            if args['save']:\n",
    "                img = io.imread(sample[\"im_name\"][0])\n",
    "                label = visualizer.label2colormap(label.numpy())\n",
    "                class_pred = visualizer.label2colormap(class_pred.cpu().numpy())\n",
    "                \n",
    "                ground_truth = visualizer.overlay_image(img[...,:3],label)\n",
    "                grid = np.concatenate((ground_truth,class_pred),axis=1)\n",
    "                base, _ = os.path.splitext(os.path.basename(sample['im_name'][0]))\n",
    "                io.imsave(os.path.join(args['save_dir'], base+'.png'),grid)\n",
    "        metrics.log(\"evaluation_deeplab.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a512f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args =get_args()\n",
    "# begin_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b4df0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuda': True,\n",
       " 'display': True,\n",
       " 'save': True,\n",
       " 'save_dir': './test_deepLabv3_2',\n",
       " 'checkpoint_path': './deepLabv3/checkpoint.pth',\n",
       " 'color_map': {0: (0, 0, 0),\n",
       "  1: (21, 176, 26),\n",
       "  2: (5, 73, 7),\n",
       "  3: (170, 166, 98),\n",
       "  4: (229, 0, 0),\n",
       "  5: (140, 0, 15)},\n",
       " 'num_class': 6,\n",
       " 'dataset': {'name': 'H2giga',\n",
       "  'kwargs': {'root_dir': '../Data',\n",
       "   'type': '20220715',\n",
       "   'class_id': None,\n",
       "   'transform': Compose(\n",
       "       <utils.transforms.ToTensor object at 0x7ff062bc1580>\n",
       "   )}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb2cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
