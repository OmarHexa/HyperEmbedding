{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.process_data import split_train_val, get_data_properties\n",
    "# from utils.generate_crops import *\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`../Data/H2giga` is choosen as datapath\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../Data'\n",
    "project_name = 'H2giga'\n",
    "if os.path.exists(os.path.join(data_dir,project_name)):\n",
    "    print(\"`{}` is choosen as datapath\".format(os.path.join(data_dir,project_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:47<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances per class\n",
      " {1: 134, 2: 166, 3: 167, 4: 133, 5: 76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:04<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreground weight of the `H2giga` dataset set equal to '{1.0: 7.841997775182617, 2.0: 6.839477258384389, 3.0: 5.68335084423856, 4.0: 9.029515782252188, 5.0: 9.533586911797785}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:45<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum object size of the `H2giga` dataset is equal to 443\n",
      "Mean object size of the `H2giga` dataset is equal to 8165.266272189349\n",
      "Maximum object size of the `H2giga` dataset is equal to 33944\n",
      "Average object size of the `H2giga` dataset along `x` is equal to 102.694\n",
      "Std. dev object size of the `H2giga` dataset along `x` is equal to 54.010\n",
      "Average object size of the `H2giga` dataset along `y` is equal to 112.331\n",
      "Std. dev object size of the `H2giga` dataset along `y` is equal to 60.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile size of the `H2giga` dataset set equal to (1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_properties_dir = get_data_properties(data_dir, project_name, train_val_name=['train', 'val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop size in x and y will be set equal to 416\n"
     ]
    }
   ],
   "source": [
    "# n_sigma is used to control the size of crop\n",
    "n_sigma = 5\n",
    "\n",
    "\n",
    "def round_up_8(x):\n",
    "    return (x.astype(int)+7) & (-8)\n",
    "\n",
    "\n",
    "crops_dir = '../crops/'\n",
    "data_subsets = ['train', 'val'] \n",
    "crop_size =416\n",
    "# crop_size = np.maximum(round_up_8(data_properties_dir['avg_object_size_y'] + n_sigma*data_properties_dir['stdev_object_size_y']),\n",
    "# round_up_8(data_properties_dir['avg_object_size_x'] + n_sigma*data_properties_dir['stdev_object_size_x']))\n",
    "print(\"Crop size in x and y will be set equal to {}\".format(crop_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/faruk92/miniconda3/lib/python3.9/site-packages/spectral/io/envi.py:175: UserWarning: Parameters with non-lowercase names encountered and converted to lowercase. To retain source file parameter name capitalization, set spectral.settings.envi_support_nonlowercase_params to True.\n",
      "  warnings.warn(msg)\n",
      "spectral:WARNING: Unable to parse bad band list (bbl) in ENVI header as integers.\n",
      "100%|██████████| 1/1 [01:58<00:00, 118.94s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/faruk92/miniconda3/lib/python3.9/site-packages/spectral/io/envi.py:175: UserWarning: Parameters with non-lowercase names encountered and converted to lowercase. To retain source file parameter name capitalization, set spectral.settings.envi_support_nonlowercase_params to True.\n",
      "  warnings.warn(msg)\n",
      "spectral:WARNING: Unable to parse bad band list (bbl) in ENVI header as integers.\n",
      "100%|██████████| 1/1 [01:54<00:00, 114.36s/it]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "for data_subset in data_subsets:\n",
    "    image_dir = os.path.join(data_dir, project_name, data_subset, 'images')\n",
    "    instance_dir = os.path.join(data_dir, project_name, data_subset,'instances')\n",
    "    classmap_dir = os.path.join(data_dir, project_name, data_subset,'classmaps')\n",
    "    hs_dir = os.path.join(data_dir, project_name, data_subset,'hs')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    image_names = sorted(glob.glob(os.path.join(image_dir, '*.png'))) \n",
    "    instance_names = sorted(glob.glob(os.path.join(instance_dir, '*.png')))\n",
    "    classmap_names = sorted(glob.glob(os.path.join(classmap_dir, '*.png')))\n",
    "    hs_names = sorted(glob.glob(os.path.join(hs_dir, '*.cue')))\n",
    "    header_names = sorted(glob.glob(os.path.join(hs_dir, '*.hdr')))\n",
    "    crop_size_iter = list(itertools.repeat(crop_size,len(image_names)))\n",
    "    crop_dir_iter = list(itertools.repeat(os.path.join(crops_dir,'H2giga'),len(image_names)))\n",
    "    type_iter = list(itertools.repeat(data_subset,len(image_names)))\n",
    "\n",
    "    \n",
    "    item = zip(image_names,instance_names,classmap_names,hs_names,header_names,crop_size_iter,crop_dir_iter,type_iter)\n",
    "    \n",
    "    with Pool(2) as p:\n",
    "        max_ = len(image_names)\n",
    "        with tqdm(total=max_) as pbar:\n",
    "            for _ in p.imap_unordered(process_with_pool, item):\n",
    "                pbar.update()\n",
    "        # shutdown the process pool\n",
    "        p.close()\n",
    "        # wait for all issued task to complete\n",
    "        p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ce193ec9d25091872f42330e8e59302c7697927f9e76d82d294f5bce38f4b24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
